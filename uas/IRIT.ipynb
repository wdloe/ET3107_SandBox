{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither path to an image or path to video provided\n",
      "Starting Inference on Webcam\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-98f343468f70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mvid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                         \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import cv2 as cv\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from yolo_utils import infer_image, show_image\n",
    "\n",
    "FLAGS = []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\n",
    "\tparser.add_argument('-m', '--model-path',\n",
    "\t\ttype=str,\n",
    "\t\tdefault='./yolov3-coco/',\n",
    "\t\thelp='The directory where the model weights and \\\n",
    "\t\t\t  configuration files are.')\n",
    "\n",
    "\tparser.add_argument('-w', '--weights',\n",
    "\t\ttype=str,\n",
    "\t\tdefault='./yolov3-coco/yolov3.weights',\n",
    "\t\thelp='Path to the file which contains the weights \\\n",
    "\t\t\t \tfor YOLOv3.')\n",
    "\n",
    "\tparser.add_argument('-cfg', '--config',\n",
    "\t\ttype=str,\n",
    "\t\tdefault='./yolov3-coco/yolov3.cfg',\n",
    "\t\thelp='Path to the configuration file for the YOLOv3 model.')\n",
    "\n",
    "\tparser.add_argument('-i', '--image-path',\n",
    "\t\ttype=str,\n",
    "\t\thelp='The path to the image file')\n",
    "\n",
    "\tparser.add_argument('-v', '--video-path',\n",
    "\t\ttype=str,\n",
    "\t\thelp='The path to the video file')\n",
    "\n",
    "\n",
    "\tparser.add_argument('-vo', '--video-output-path',\n",
    "\t\ttype=str,\n",
    "        default='./output.avi',\n",
    "\t\thelp='The path of the output video file')\n",
    "\n",
    "\tparser.add_argument('-l', '--labels',\n",
    "\t\ttype=str,\n",
    "\t\tdefault='./yolov3-coco/coco-labels',\n",
    "\t\thelp='Path to the file having the \\\n",
    "\t\t\t\t\tlabels in a new-line seperated way.')\n",
    "\n",
    "\tparser.add_argument('-c', '--confidence',\n",
    "\t\ttype=float,\n",
    "\t\tdefault=0.5,\n",
    "\t\thelp='The model will reject boundaries which has a \\\n",
    "\t\t\t\tprobabiity less than the confidence value. \\\n",
    "\t\t\t\tdefault: 0.5')\n",
    "\n",
    "\tparser.add_argument('-th', '--threshold',\n",
    "\t\ttype=float,\n",
    "\t\tdefault=0.3,\n",
    "\t\thelp='The threshold to use when applying the \\\n",
    "\t\t\t\tNon-Max Suppresion')\n",
    "\n",
    "\tparser.add_argument('--download-model',\n",
    "\t\ttype=bool,\n",
    "\t\tdefault=False,\n",
    "\t\thelp='Set to True, if the model weights and configurations \\\n",
    "\t\t\t\tare not present on your local machine.')\n",
    "\n",
    "\tparser.add_argument('-t', '--show-time',\n",
    "\t\ttype=bool,\n",
    "\t\tdefault=False,\n",
    "\t\thelp='Show the time taken to infer each image.')\n",
    "\n",
    "\tFLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "\t# Download the YOLOv3 models if needed\n",
    "\tif FLAGS.download_model:\n",
    "\t\tsubprocess.call(['./yolov3-coco/get_model.sh'])\n",
    "\n",
    "\t# Get the labels\n",
    "\tlabels = open(FLAGS.labels).read().strip().split('\\n')\n",
    "\n",
    "\t# Intializing colors to represent each label uniquely\n",
    "\tcolors = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n",
    "\n",
    "\t# Load the weights and configutation to form the pretrained YOLOv3 model\n",
    "\tnet = cv.dnn.readNetFromDarknet(FLAGS.config, FLAGS.weights)\n",
    "\n",
    "\t# Get the output layer names of the model\n",
    "\tlayer_names = net.getLayerNames()\n",
    "\tlayer_names = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        \n",
    "\t# If both image and video files are given then raise error\n",
    "\tif FLAGS.image_path is None and FLAGS.video_path is None:\n",
    "\t    print ('Neither path to an image or path to video provided')\n",
    "\t    print ('Starting Inference on Webcam')\n",
    "\n",
    "\t# Do inference with given image\n",
    "\tif FLAGS.image_path:\n",
    "\t\t# Read the image\n",
    "\t\ttry:\n",
    "\t\t\timg = cv.imread(FLAGS.image_path)\n",
    "\t\t\theight, width = img.shape[:2]\n",
    "\t\texcept:\n",
    "\t\t\traise 'Image cannot be loaded!\\n\\\n",
    "                               Please check the path provided!'\n",
    "\n",
    "\t\tfinally:\n",
    "\t\t\timg, _, _, _, _ = infer_image(net, layer_names, height, width, img, colors, labels, FLAGS)\n",
    "\t\t\tshow_image(img)\n",
    "\n",
    "\telif FLAGS.video_path:\n",
    "\t\t# Read the video\n",
    "\t\ttry:\n",
    "\t\t\tvid = cv.VideoCapture(FLAGS.video_path)\n",
    "\t\t\theight, width = None, None\n",
    "\t\t\twriter = None\n",
    "\t\texcept:\n",
    "\t\t\traise 'Video cannot be loaded!\\n\\\n",
    "                               Please check the path provided!'\n",
    "\n",
    "\t\tfinally:\n",
    "\t\t\twhile True:\n",
    "\t\t\t\tgrabbed, frame = vid.read()\n",
    "\n",
    "\t\t\t    # Checking if the complete video is read\n",
    "\t\t\t\tif not grabbed:\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\tif width is None or height is None:\n",
    "\t\t\t\t\theight, width = frame.shape[:2]\n",
    "\n",
    "\t\t\t\tframe, _, _, _, _ = infer_image(net, layer_names, height, width, frame, colors, labels, FLAGS)\n",
    "\n",
    "\t\t\t\tif writer is None:\n",
    "\t\t\t\t\t# Initialize the video writer\n",
    "\t\t\t\t\tfourcc = cv.VideoWriter_fourcc(*\"MJPG\")\n",
    "\t\t\t\t\twriter = cv.VideoWriter(FLAGS.video_output_path, fourcc, 30, \n",
    "\t\t\t\t\t\t            (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "\n",
    "\t\t\t\twriter.write(frame)\n",
    "\n",
    "\t\t\tprint (\"[INFO] Cleaning up...\")\n",
    "\t\t\twriter.release()\n",
    "\t\t\tvid.release()\n",
    "\n",
    "\n",
    "\telse:\n",
    "\t\t# Infer real-time on webcam\n",
    "\t\tcount = 0\n",
    "\n",
    "\t\tvid = cv.VideoCapture(0)\n",
    "\t\twhile True:\n",
    "\t\t\t_, frame = vid.read()\n",
    "\t\t\theight, width = frame.shape[:2]\n",
    "\n",
    "\t\t\tif count == 0:\n",
    "\t\t\t\tframe, boxes, confidences, classids, idxs = infer_image(net, layer_names, \\\n",
    "\t\t    \t\t\t\t\t\theight, width, frame, colors, labels, FLAGS)\n",
    "\t\t\t\tcount += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tframe, boxes, confidences, classids, idxs = infer_image(net, layer_names, \\\n",
    "\t\t    \t\t\t\t\t\theight, width, frame, colors, labels, FLAGS, boxes, confidences, classids, idxs, infer=False)\n",
    "\t\t\t\tcount = (count + 1) % 6\n",
    "\n",
    "\t\t\tcv.imshow('webcam', frame)\n",
    "\t\t\t\n",
    "\t\t\t#print(classids)\n",
    "\t\t\t#Human Recognition by IRIT\n",
    "\t\t\t\n",
    "\t\t\tif 0 in classids:\n",
    "\t\t\t\tprint(\"1\") # Manusia terdeteksi dengan notasi 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"0\") # tidak ada manusia yang terdeteksi\n",
    "\n",
    "\t\t\tif cv.waitKey(1) & 0xFF == ord('q'):\n",
    "\t\t\t\tbreak\n",
    "\t\tvid.release()\n",
    "\t\tcv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
